			+--------------------+
			|       ECE 434      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Yang Zhang <zhang.yang.frank@gmail.com>
Naixuan Ma <nm538@scarletmail.rutgers.edu>
Tong Wang  <tony.wang0512@gmail.com>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Online sources:
[1] http://zhangyangfrank.com/log-of-bochs-qemu-and-pintos-installation-on-ubuntu-14-04/
[2] http://spsneo.com/blog/2008/08/03/how-to-install-pintos-on-qemu/
[3] https://tssurya.wordpress.com/2014/10/25/priority-scheduling-inversion-and-donation/
[4] https://pintosiiith.wordpress.com/category/pintos/
[5] https://github.com/microdog/pintos-project-1
[6] https://github.com/ryantimwilson/Pintos-Project-1
[7] https://github.com/andrei-alpha/pintos/commit/f632b1e1de37074246a25b6784a2dfb8bb826863


			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

src/devices/timer.c
	struct list sleeping_list;	/* Put the thread into this list 
					   to sleep */
src/threads/thread.h
	int wakeup_ticks;               /* Record the sleep interval or when 
					   the thread is ready to be unblocked */

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

In timer_sleep():
1) Turn off the interrupt.
2) Get the current running thread.
3) Calculate the wake up time for this thread by adding the ticks argument 
to the current ticks(since the OS boots) and store it to the new created 
variable wakeup_ticks.
4) Use the list_insert_ordered() function to add the thread into sleeping_list by 
decending order, we need to provide an LESS function. The soon to be ran thread will
stay in front of the list.
5) Block the thread.
6) Turn on the interrrupt.

In the timer interrupt handler:
We developed a function called wakeup_thread():
1) Check whether the sleeping_list is empty or not, if it's empty, there's nothing to
wake up, if it's not, we will proceed to the next step.
2) Get the frontest thread in the sleeping_list.
3) Check the thread's tick with global one(compare the time). If the thread's ticks 
value <= the OS ticks, the thread is removed from the sleeping_list and unblocked, 
if it's not, finish the check and continue the CPU task.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?
We keep threads sorted in the sleeping_list when we do the insertion. Thus every time 
the handler doesn't go through the whole list to find out which thread to be unblocked, 
which minimize the amount of time spent in the handler.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?
We solve the 2 problems above both by disabling the interrupt in step 1). Since the 
sleeping_list is a kernel structure, the other threads won't touch it during the 
interrupt.This will make sure threads are using this function sequentially. Race 
conditions can also be avoided.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
We try to implement the functions based on the orignal function of Pintos. We have tried
to add a new state called SLEEPING, and then changed threads state. However, it made code
much more messy and since there's a structure called ready list, we imitate it and have 
another list to keep sleeping thread.  

When it comes to sorting the list, we go through all the exsiting functions and find 
list_insert_ordered() which makes the code clean and neat. We tried our best to implement the
function and maintain the original structure.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
src/threads/thread.h
	#define PRIDON_MAX_DEPTH 9              /* Max depth of nested donation. */
	struct list locks;                      /* Locks held for priority donation. */
	struct lock *lock_waiting;              /* Lock waiting on for priority donation. */
	int temp_priority;                      /* For priority comparison use. */

src/threads/synch.h
				 /* Change the structure of Lock. */
     struct list_elem elem;      /* List element for priority donation. */
     int max_priority;           /* Max priority for priority donation. */

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)
We create a new sorted list called "locks" to store the priority donations of 
each thread. We also create lock add/remove functions to change the priority when
the main calls lock_aquire() or lock_release(). We let the program to go through 
all the locks list to check the donation relationship between different threads.
As it traverses the list, it can update all the priorities in this donation list.

Nested Donation Example:
A, B, C are 3 threads, A is the main thread with the minmum priority 3, and it 
aquires the lock first; then B, C are created and aquire the lock one by one, their
priority are 6 and 9 respectively.
A----priority->3
  |--list->[A]
  |--locker->L1

Then B is created, it will update A's thread structure;
A----priority->6 ----B----priority->6
  |--list->[A]	        |--list->[B,A]
  |--locker->NULL       |--locker->L1

Then C is created, it will again update all the thread in locks list.
A----priority->9 ----B----priority->9 ----C----priority->9
  |--list->[A]	        |--list->[B,A]       |--list->[C,B,A]
  |--locker->NULL       |--locker->L1        |--locker->L2


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
In a semaphore or condition variable or a lock, we make sure waiters are inserted
in a descending order by this function list_insert_ordered(). The front thread thus
will have highest priority. We need to implement the comparison function for each
insertion. 

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
1) Init the depth to 0;
2) Check whether the lock is held by other threads;
3) If there's other thread holds the lock:
	store the lock to current thread;
	Do a while loop with max iteration == 9;
	In the loop, donate the current thread's priority to next thread;
	Also update all the donation list(locks).
4) Update the thread and lock information;
5) Add lock to the thread;
   
>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
1) Remove the lock from locks list;
2) Update the priority;
3) Reorder the current thread's priority list;
4) The lock holder is updated to NULL.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?
A possible race case is that when we're updating the priority of current
thread, the interrupt handler is also manipulating the priority variable.The thread_set_priority 
must determine whether or not to yield, which requires determining the current highest-priority 
thread in the ready list. Doing so requires accessing the ready list, which is a shared structure.

We could avoid this by turning off the interrupt during the thread_set_priority()
function. We need to write and read the priority in interrupt handler which can't acquire
locks, thus we can't use a lock to avoid the race.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
Like what we did in the alarm-clock task, we tried to modify as little code as
possible and maintain the original structure. Then we borrow the list structure from
the lib and did the minmum change.

Also, we could make sure the list is sorted after we insert one thread and we don't 
need to sort them which is efficient.

Last but not least, our implementation could make the nest donation as deep as possible, when the 
memory is available.
			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
src/threads/thread.h
	int nice;                           /* Niceness for BSD scheduler. */
	fixed_t recent_cpu;                 /* Recent CPU for BSD scheduler. */
src/threads/thread.c
	fixed_t load_avg;		    /* Load average for BSD scheduling */

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59   A
 4      4   0   0  62  61  59   A
 8      8   0   0  61  61  59   B
12      8   4   0  61  60  59   A
16     12   4   0  60  60  59   B
20     12   8   0  60  59  59   A
24     16   8   0  59  59  59   C
28     16   8   4  59  59  58   B
32     16  12   4  59  58  58   A
36     20  12   4  58  58  58   C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?
The ambiguity that makes values uncertain is that when 2 threads have the 
same priority, the scheduluer doesn't know which thread to run first.

The rule is to run the thread which isn't selected within the most nearest
ticks. For example, when it comes to ticks 8 in above example, since A and B
have the same priority but B doesn't run recently, B will become the next thread 
to run.

It matches the behavior of our scheduler becaue we're inserting the thread behind
the existing thread when they have the same priorities. Thus no thread
will dominate the system even though multiple threads have the same priority.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?
We only update the priorities and recent_cpu when schedule is called which is
approximately every four ticks instead of every tick thus avoiding some
unnecessary calculations. 
If we put too many steps inside the interrupt then it will has an issue like the doc
in mlfqs_load_avg.c said:
"  If the timer interrupt handler takes too
   long, then the test's main thread will not have enough time to
   do its own work (printing a message) and go back to sleep
   before the next tick arrives.  Then the main thread will be
   ready, instead of sleeping, when the tick arrives,
   artificially driving up the load average."

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?
Advantage:
(1) We make full use of the original functions and the structure, thus 
our implementation is clear in structure and has high stability;
(2) The list to keep threads in our design is always sorted which make it
very quick to select the next thread and keep the running order and follow 
fair round robin rule.
(3) We doesn't add too many variables and arguments and save the memory.

Improvement:
We need much more time to focus on the calculation of recent_cpu, its position 
really does influence the performance of the tests. We should try different inside 
and outside combinations.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?
We implemented fixed-point.h file and in this file we define all the functions 
it needs by definition. We do this to keep it more clear for users to use the fixed_point
values and operations. 

Also, it's very convient to change and update the function if the formula has changed or 
we want to add some additional values. Doing so could increase the extensibility of the code.


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?
It's a little hard, without any hint or reference, it's very hard to figure out
an own design. Maybe you could provide more design suggestions or guides in the 
following assignments.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?
Yes, especially the 2nd task, priority scheduling. I have a better understand of 
the semaphore, lock and cond after I go through the code and try different implementations.

The priority donation is very interesting and also important that I think everyone should work
on it by himself or herself.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?
I think you should provide more detailed environment guide at the beginning of the lab. We've spent
half of our time just trying to find a correct Linux version to run the virtual machine and install
the Pintos. If we know more about the the env, we can spend much more time on the real problems.

>> Any other comments?
We want give special thank to Antons who gave us a lot of help. He replied the email quickly and gave
us very specific solutions. He did a great job. Thanks to him, we can finish the project on time.
